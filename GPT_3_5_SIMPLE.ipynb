{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to run the command below to upgrade OpenAI API in order to use ChatGPT. The older version will not work with ChatGPT.\n",
    "You will have to do it only once, than comment out the \"!pip install --upgrade openai\" command.\n",
    "\n",
    "The previous version of this notebook will not work, because queries to GPT-3 and ChatGPT (GPT-3.5 turbo)\n",
    "are run differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/PeterS111/GPT-3_various/blob/GPT_3_5_SIMPLE.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"YOUR_KEY_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(out_text):\n",
    "\n",
    "    index = 1\n",
    "\n",
    "    out_file = \"GPT-3_5_\"        \n",
    "    out_file_name = out_file + str(index) + \".txt\"\n",
    "\n",
    "    while out_file_name in os.listdir():\n",
    "        index +=1\n",
    "        out_file_name = out_file + str(index) + \".txt\"\n",
    "        if out_file_name not in os.listdir():\n",
    "            break\n",
    "\n",
    "    f= open(out_file_name, \"a\", encoding = \"utf-8\")\n",
    "    f.write(out_text)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def run_gpt3_5(in_str):\n",
    "    response = openai.ChatCompletion.create(\n",
    "       model=\"gpt-3.5-turbo\",\n",
    "       temperature=1,\n",
    "       messages=[\n",
    "             {\"role\": \"system\", \"content\": in_str}\n",
    "         ]\n",
    "    )\n",
    "   \n",
    "    answer = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    return answer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDIT THE PROMPT AS REQUIRED:  ########\n",
    "\n",
    "prompt = \"\"\"What should I do with GPT?\"\"\"\n",
    "\n",
    "#########################################\n",
    "\n",
    "\n",
    "response = run_gpt3_5(prompt)\n",
    "out_text = prompt + \"\\n\\nRESPOSE GPT-3.5:\\n\\n\" + response\n",
    "print(out_text)\n",
    "write_to_file(out_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
